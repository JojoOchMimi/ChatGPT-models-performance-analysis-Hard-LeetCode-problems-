# ChatGPT Models LeetCode Performance Analysis

This repository contains the results and statistical analysis of two experiments comparing the performance of three ChatGPT modelsâ€”**GPT-3.5**, **GPT-4o**, and **o1**â€”on solving hard coding problems from **LeetCode**.

## ğŸ“Š Overview

The experiments were designed to evaluate how effectively each model solves coding challenges, using two different scoring approaches:

- **Aggregated Approach (2-out-of-3):** A problem is considered solved if a model solves it at least 2 out of 3 times.
- **Proportional Approach:** Scores are assigned based on how many of the 3 attempts were successful (0%, 33.33%, 66.67%, 100%).

## ğŸ“ Repository Structure

```plaintext
ğŸ“‚ experiment-results/
    â”œâ”€â”€ Main experiment results of o1
    â”œâ”€â”€ Main experiment results of 4o
    â”œâ”€â”€ Main experiment results of 3.5
    â”œâ”€â”€ Post-experiment results of o1
    â””â”€â”€ Post-experiment results of 4o

ğŸ“‚ unsolved-problems/
    â”œâ”€â”€ Unsolved problems by models in Main experiment
    â””â”€â”€ Unsolved problems by models in Post-experiment

ğŸ“‚ statistical-analysis/
    â”œâ”€â”€ Pairwise p-value (Aggregated Approach, n=60)
    â”œâ”€â”€ Pairwise p-value (Proportional Approach, n=30)
    â”œâ”€â”€ Wald Confidence Interval (Aggregated Approach, n=60)
    â””â”€â”€ Wald Confidence Interval (Proportional Approach, n=30)
